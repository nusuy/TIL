# Machine Learning

> Multi Layer Perceptron은 Deep Learning

- Learn from Data / Function Approximation (출력과 입력 사이 `f(x)` 찾기)

## 머신러닝 적용 조건

1. 데이터 수집 가능
2. 규칙 존재
3. 기존 명시적 프로그래밍 방법으로 해결 불가한 문제

- 입력: 독립변수, X, 특성, feature
- 출력: 종속변수, Y, 타깃값, Label(분류), 클래스

- 사례 기반 학습: 기존 데이터 학습 후 새로운 데이터와 기존 데이터의 유사도 측정 후 결정
- 모델 기반 학습: 기존 데이터에서 규칙(모델, 함수) 탐색 후 규칙(모델) 이용하여 예측

### 지도 학습

1. 회귀(Regression): Y 변수(타깃값)이 연속형, 수치 예측
   기존 데이터를 잘 표현하는 직선
2. 분류(Classification): Y 변수(타깃값)이 범주형, 범주 예측
   기존 데이터를 잘 나눌 수 있는 직선

### 비지도 학습

> 학습 데이터에서 타깃값이 미포함 / 수집 불가

- 군집(Clustering): 타깃 변수 X, 특성 비슷한 데이터로 묶음
- 차원축소(Dimension Reduction): 투영(3->2 차원)

### 학습 vs. 검증 vs. 테스트 데이터

- 테스트 데이터는 학습에 사용되지 않음
- Test 데이터는 전체 array에서 제외
- validation: 학습에 참여 (알고리즘에 입력되지는 않지만, 검증 데이터에 맞게 모델을 만들어 가는 것)

## 교차 검증

Cross-Validation

- 가장 적합한 모델 선택 위해
- 학습 세트를 여러 서브셋으로 분리, 모델을 각 서브셋의 조합으로 훈련 후 검증 (평균값 사용)
- 학습이 끝나면 최종 모델을 전체 학습 세트로 학습

## 인코딩

- 문자열 데이터(범주형) -> 숫자 변환 전처리

### 라벨 인코딩 (Label Encoding)

### 원-핫 인코딩

- 가까이 있는 두 값이 떨어져 있는 두 값보다 더 비슷하다고 판단하는 알고리즘 오류 방지
- 더 큰 값(숫자)을 더 중요하다고 판단하는 알고리즘 오류 방지

## 스케일링

### 특성 스케일링

> 표준화, 정규화
> KNN SVM Clustering

- 수치형 변수에만 적용 (값 조정 과정이므로)
- 각 feature가 동일한 중요도를 가짐을 알고리즘이 이해하도록 (알고리즘이 수치값에 따라 중요도를 다르게 판단하는 경우 방지)
- 이상치 때문에 평균값 사용 불가 -> median 값

#### 이상치 판단

- 분포도, 박스플롯으로 확인
- 데이터 분석 전 데이터에 대한 도메인 지식 / 각 컬럼의 의미를 알아야 정확한 이상치 판단이 가능

#### 결측치

- 데이터 버리거나 값 채우기

#### 불균형 데이터

- 오버 샘플링: 소수 클래스의 샘플 늘리기(Resampling, SMOTE, ADASYN)
- 언더 샘플링: 다수 클래스의 샘플 줄이기

## 좋은 모델

1. 학습 데이터를 잘 설명
2. 새로운 데이터 (미래 데이터)에 대한 예측 -> **일반화**

## Over-Fitting / Under-Fitting

- 모델을 지나치게 학습 -> 학습 데이터셋에서는 모델 성능 높지만 새로운 데이터에 대해서는 정확한 예측 / 분류 불가
- 학습 중 Overfit 방지 위한 규제

## 파라미터

### Hyper-Parameter

- 학습 모델(알고리즘)의 설정을 위해 사람이 직접 설정하는 값
- learning rate, mini-batch size, epoch ...

### 모델 파라미터

- 모델이 학습되며 자동 결정되는 모델 내부 파라미터

### 하이퍼 파라미터 튜닝

- 최적의 하이퍼-파라미터 탐색

## 오차 행렬

> 혼동 행렬, Confusion Matrix

### F1 Score

- Precision과 Recall을 하나의 숫자로 표현
- 정밀도와 재현율의 조화 평균 -> 둘이 비슷할 수록 F1 Score 높아짐
- 0 ~ 1

### ROC

> Receiver operating characteristic

- Threshold 값 변화에 따른 True Positive Ratio와 False Positive Ratio 그래프
- ROC 커브가 좌 상단에 붙어있는 것이 더 좋은 분류기

## 회귀 알고리즘 평가

### 회귀 알고리즘

- 오차 최소화 위해 모델(선의 식) 최적화
- MSE (Mean Squared Error)
- Root MSE
- Mean Absolute Error

#### 결정계수 R Square

- 회귀 알고리즘 적용 전, y값 평균과 전체 데이터 사이 오차 계산

## kNN K-Nearest Neighbor 실습

- K 의 적절한 설정이 중요

### 거리 계산

> 유사성 (유사도) 계산

1. 유클리드 거리
2. 맨하탄 거리

### K 값에 따른 분류

- K = 1인 경우 과대적합 발생
- K 값 커질수록 결정경계 완만하지만 과소적합 발생 가능

#### 분류

> 구분 중요

- 이진 분류: 두 가지로 분류
- 다중 분류: 여러 가지로 분류

# Support Vector Machine

- 두 개의 클래스 분류하는 많은 직선 중 가장 좋은 직선 선택

## HardMargin Classification

- 데이터가 모두 서포트 벡터 바깥에 존재

## SoftMargin Classification

- 에러 고려하는 서포트 벡터 머신 모델
- 과적합 방지 위한 규제

## Hyper Parameter

- C, gamma
- 선형, 비선형 분류 모두 사용 가능
  - 비선형: 다차원 변환 후 선형 분류 (원래 차원에서는 비선형)
- 이진 분류만 가능
  - One-versus-Rest (OVR): `1:나머지`
